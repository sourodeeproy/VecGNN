{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install dgl\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFoKay1x8wlb",
        "outputId": "9886906e-6771-43c5-9034-9d3769c2cf8e"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph\n",
        "\n",
        "\n",
        "gcn_msg = fn.copy_src(src='h', out='m')\n",
        "gcn_reduce = fn.sum(msg='m', out='h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBCAgdF_L_ep"
      },
      "outputs": [],
      "source": [
        "#from sklearn.datasets import fetch_mldata\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "#from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJLvldFJnUTL"
      },
      "outputs": [],
      "source": [
        "#message passing function\n",
        "#formatting this one \n",
        "import math\n",
        "import torch\n",
        "import numpy \n",
        "def find_common_in_nbrs(g, i, j):\n",
        "    \"\"\"Find nodes that have edges to both node i and node j.\n",
        "    \n",
        "    Returns\n",
        "    --------\n",
        "    NumPy array of int64\n",
        "    \"\"\"\n",
        "    return len(numpy.intersect1d(g.in_edges(i)[0], g.in_edges(j)[0])),len(numpy.union1d(g.in_edges(i)[0], g.in_edges(j)[0]))\n",
        "\n",
        "\n",
        "def my_msg(edges):\n",
        "    x = edges.src['h']\n",
        "    (a,b)=x.size()\n",
        "    src, dst, _ = edges.edges()\n",
        "    source_nd = src.detach().numpy()\n",
        "    destin_nd = src.detach().numpy()\n",
        "    #print(src)\n",
        "    my_wei_product=np.zeros(a)\n",
        "    \n",
        "    yo_2 = g.out_degrees(source_nd).detach().numpy()    \n",
        "    yo_1 = g.out_degrees(destin_nd).detach().numpy()\n",
        "    summation =0\n",
        "     \n",
        "    for i in range(a):\n",
        "        inter, union = find_common_in_nbrs(g, source_nd[i], destin_nd[i])\n",
        "        my_wei_product[i]= (inter/union)#math.sqrt((yo_2[i])*(yo_1[i]))\n",
        "       # summation = summation + my_wei_product[i]\n",
        "       # if (my_wei_product[i]<0.25):\n",
        "       #    my_wei_product[i] = 0\n",
        "       # if (my_wei_product[i]<0.5):\n",
        "       #    my_wei_product[i] = 0.5  \n",
        "       # if (my_wei_product[i]<0.75):\n",
        "       #    my_wei_product[i] = 1 \n",
        "       # else:\n",
        "       #    my_wei_product[i] = 2 \n",
        "       #     '''\n",
        "    #for i in range(a):\n",
        "        x[i,:] = x[i,:] * (math.exp(my_wei_product[i]))#\\/summation) \n",
        "\n",
        "    return {'m': x}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGH-QHhrngGO"
      },
      "outputs": [],
      "source": [
        "#aggregator function\n",
        "def my_reduce(nodes):#aggregator function \n",
        "    messages_neg = nodes.mailbox['m']\n",
        "    x = nodes.mailbox['m'].detach().numpy()\n",
        "    a,b,c = messages_neg.size()#(N,D,feature_size)\n",
        "    y = nodes.data['h'].detach().numpy() #(N,feature_size)\n",
        "    my_dot_product=np.zeros((a,b))\n",
        "    for i in range(a):\n",
        "        for j in range(b):\n",
        "                    #my_dot_product[i,j] = 2+(np.dot(x[i,j,:],y[i,:])/ (np.linalg.norm(x[i,j,:])* np.linalg.norm(y[i,:])))\n",
        "            my_dot_product[i,j] = ((1+(np.dot(x[i,j,:],y[i,:])/ (np.linalg.norm(x[i,j,:])*np.linalg.norm(y[i,:])))))\n",
        "            messages_neg[i,j,:] = messages_neg[i,j,:]*my_dot_product[i,j]\n",
        "    agg_=torch.sum(messages_neg, dim=1)\n",
        "    #agg_=torch.mean(messages_neg, dim=1)\n",
        "    #agg_=messages_neg.sum(1)\n",
        "    return {'h': agg_}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8lNAmM492lH"
      },
      "outputs": [],
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Creating a local scope so that all the stored ndata and edata\n",
        "        # (such as the `'h'` ndata below) are automatically popped out\n",
        "        # when the scope exits.\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = feature\n",
        "            g.update_all(my_msg,  my_reduce)\n",
        "            #g.update_all(gcn_msg, gcn_reduce)\n",
        "            h = g.ndata['h']\n",
        "            return self.linear(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhAtaZm-93gy",
        "outputId": "b555e490-ea51-446f-fd6a-b9ac1c0ad727"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layer1 = GCNLayer(1433, 16)#1433 for cora, 500, 1024,3703 for citseer  \n",
        "        self.layer2 = GCNLayer(16, 7)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = F.relu(self.layer1(g, features))\n",
        "        x = self.layer2(g, x)\n",
        "        #print(\"The proba vector is\",x,'and its size is',x.shape)\n",
        "        return x\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta6A3D9lnaKK"
      },
      "outputs": [],
      "source": [
        "from dgl import DGLGraph\n",
        "from dgl.data import citation_graph as citegrh\n",
        "import networkx as nx\n",
        "from dgl.data import CiteseerGraphDataset,CoraGraphDataset\n",
        "import numpy as np\n",
        "def load_cora_data():\n",
        "    dataset = CoraGraphDataset()\n",
        "    g = dataset[0]\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = np.add(g.ndata['val_mask'], g.ndata['train_mask'])\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    #print(train_mask.shape())\n",
        "    n = g.ndata['val_mask'].size()\n",
        "    n=n[0]\n",
        "    print(n)\n",
        "    for i in range(n):\n",
        "        train_mask[i] = False\n",
        "        test_mask[i] = False\n",
        "    \n",
        "    train = (int)(n*0.3)\n",
        "    \n",
        "    for i in range(train):\n",
        "        train_mask[i] = True\n",
        "    \n",
        "    for i in range(train,n-(int)(n*0.1)):\n",
        "        test_mask[i] = True\n",
        "\n",
        "\n",
        "    return g, features, labels, train_mask, test_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "mWJqmOjo96_K",
        "outputId": "3eda3a3c-8595-486f-f350-7465d33b5500"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from dgl.data import CoraGraphDataset\n",
        "def load_cora_data():\n",
        "    dataset = CoraGraphDataset()\n",
        "    g = dataset[0]\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    n = g.ndata['train_mask'].size()\n",
        "    n=n[0]\n",
        "    print(n)\n",
        "    \n",
        "    for i in range(n):\n",
        "        train_mask[i] = False\n",
        "        test_mask[i] = False\n",
        "    \n",
        "    train=810\n",
        "    \n",
        "    for i in range(train):\n",
        "        train_mask[i] = True\n",
        "    \n",
        "    for i in range(train+1,n):\n",
        "        test_mask[i] = True\n",
        "\n",
        "    return g, features, labels, train_mask, test_mask\n",
        "\n",
        "from dgl.data import PubmedGraphDataset\n",
        "def load_pubmed_data():\n",
        "    dataset = PubmedGraphDataset()\n",
        "    g = dataset[0]\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = np.add(g.ndata['val_mask'], g.ndata['train_mask'])\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    #print(train_mask.shape())\n",
        "    n = g.ndata['val_mask'].size()\n",
        "    n=n[0]\n",
        "    print(n)\n",
        "    for i in range(n):\n",
        "        train_mask[i] = False\n",
        "        test_mask[i] = False\n",
        "    \n",
        "    train = (int)(n*0.3)\n",
        "    \n",
        "    for i in range(train):\n",
        "        train_mask[i] = True\n",
        "    \n",
        "    for i in range(train,n-331):\n",
        "        test_mask[i] = True\n",
        "\n",
        "\n",
        "    return g, features, labels, train_mask, test_mask\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvETvOb2-F9n"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, g, features, labels, mask):\n",
        "    model.eval()\n",
        "    with th.no_grad():\n",
        "        logits = model(g, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = th.max(logits, dim=1)\n",
        "        correct = th.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GF6rejUnG0l",
        "outputId": "77765a76-a7b1-48ba-c9d6-0728798cdc21"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "g, features, labels, train_mask, test_mask = load_cora_data()\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iX0Yd30-J71"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "g, features, labels, train_mask, test_mask = load_cora_data()\n",
        "# Add edges between each node and itself to preserve old node representations\n",
        "prob_y_train=[]\n",
        "g.add_edges(g.nodes(), g.nodes())\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
        "dur = []\n",
        "GNN_layer=[]\n",
        "max_accuracy=0\n",
        "log=[]\n",
        "for epoch in range(200):\n",
        "    if epoch >=3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    net.train()\n",
        "    logits= net(g, features)\n",
        "    log.append(logits)\n",
        "    \n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    prob_y_train.append(logp)\n",
        "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch >=3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    acc = evaluate(net, g, features, labels, test_mask)\n",
        "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
        "            epoch, loss.item(), acc, np.mean(dur)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYYEbfhHo79A",
        "outputId": "414c4b17-ed61-48a8-c536-328b576f207b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "2708 x 7\n"
          ]
        }
      ],
      "source": [
        "our_confidence=np.exp(prob_y_train[16].detach().numpy())\n",
        "print(type(our_confidence))\n",
        "print(len(our_confidence),'x',len(our_confidence[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15bkuTGAsi6S"
      },
      "outputs": [],
      "source": [
        "print(our_confidence)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsIhVVXD4egF"
      },
      "outputs": [],
      "source": [
        "labels=list(labels)\n",
        "okay=[]\n",
        "for i in our_confidence:\n",
        "    okay.append(list(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoGr0rK13R_K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "result_df = pd.DataFrame(list(zip(okay)),\n",
        "               columns =['confidence'])\n",
        "result_df.to_csv('/content/drive/MyDrive/Confidence/GCN.csv',sep=',', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6yYbYvMs1oW"
      },
      "outputs": [],
      "source": [
        "#writing into CSV file\n",
        "import csv\n",
        "data=[]\n",
        "\n",
        "\n",
        "header = ['0','1','2','3','4','5','6']\n",
        "#labels\n",
        "for i in labels:#our_confidence:\n",
        "    yu_mama=[0,0,0,0,0,0,0]\n",
        "    yu_mama[i]=1\n",
        "    data.append(yu_mama)\n",
        " \n",
        "\n",
        "with open('/content/drive/MyDrive/cora_dataset_label.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnrnxNiLwJyV"
      },
      "outputs": [],
      "source": [
        "#not run\n",
        "'''\n",
        "!pip install xlswriter\n",
        "import xlswriter as xv\n",
        " \n",
        "# Workbook() takes one, non-optional, argument\n",
        "# which is the filename that we want to create.\n",
        "workbook = xv.Workbook('hello.xlsx')\n",
        " \n",
        "# The workbook object is then used to add new\n",
        "# worksheet via the add_worksheet() method.\n",
        "worksheet = workbook.add_worksheet()\n",
        " \n",
        "# Use the worksheet object to write\n",
        "# data via the write() method.\n",
        "for i in our_confidence:\n",
        "    worksheet.write(i)\n",
        "\n",
        "#worksheet.write('A1', 'Hello..')\n",
        "#worksheet.write('B1', 'Geeks')\n",
        "#worksheet.write('C1', 'For')\n",
        "#worksheet.write('D1', 'Geeks')\n",
        " \n",
        "# Finally, close the Excel file\n",
        "# via the close() method.\n",
        "workbook.close()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVOEcUq8KhO3"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE as tsne \n",
        "X=np.array(features)\n",
        "X_embedded = tsne(n_components=2).fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9PGK4MLNIc8"
      },
      "outputs": [],
      "source": [
        "color=[(0,0,0), (0,0,1), (0,1,0), (1,0,0), (0,1,1), (1,0,1), (1,1,0)]\n",
        "colors=[]\n",
        "size=[]\n",
        "for i in labels:\n",
        "    colors.append(color[i+2])\n",
        "    size.append(1)\n",
        "sizes=np.asarray(size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw2LZ7jqL0nq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(x=X_embedded[:,0],y=X_embedded[:,1],s=sizes*10,c=colors)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp_jrwQcWAp2"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE as tsne \n",
        "Xr=np.array(log)\n",
        "Xr=np.transpose(Xr)\n",
        "Xr= Xr\n",
        "print(type(Xr))\n",
        "print(Xr)\n",
        "X_embedded = tsne(n_components=2).fit_transform(Xr[7].detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps3H7axzboKg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(x=X_embedded[:,0],y=X_embedded[:,1],s=sizes*10,c=colors)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_Qib12LPVtp"
      },
      "outputs": [],
      "source": [
        "lbs=np.zeros((2708,7))\n",
        "for i in range(labels.shape[0]):\n",
        "    lbs[i][labels[i]]=1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzeZFhyvJ_Qe"
      },
      "outputs": [],
      "source": [
        "#precision recall curve\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "for epoch in range(50):\n",
        "    for i in range(7):\n",
        "        yo_=prob_y_train[epoch][:][i].detach().numpy()\n",
        "        yo_=(yo_-np.min(yo_))/np.ptp(yo_)\n",
        "        #yo_=(yo_-np.mean(yo_))/np.std(yo_)\n",
        "        print(yo_)\n",
        "        precision[i], recall[i], _ = precision_recall_curve(lbs[:][i],yo_)#prob_y_train[epoch][:][i].detach().numpy()\n",
        "        #print(\"The pr and re are :\", precision[i], recall[i])\n",
        "        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
        "    \n",
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")\n",
        "\n",
        "plt.title(\"precision vs. recall curve\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaODRoLIabGx"
      },
      "outputs": [],
      "source": [
        "# roc curve\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "\n",
        "for i in range(50):\n",
        "    yo_=prob_y_train[epoch][:][i].detach().numpy()\n",
        "    yo_=(yo_-np.min(yo_))/np.ptp(yo_)\n",
        "    #yo_=(yo_-np.mean(yo_))/np.std(yo_)\n",
        "    #print(yo_)\n",
        "    fpr[i], tpr[i], _ = roc_curve(lbs[:][i],yo_)\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))\n",
        "\n",
        "plt.xlabel(\"false positive rate\")\n",
        "plt.ylabel(\"true positive rate\")\n",
        "#plt.legend(loc=\"best\")\n",
        "plt.title(\"ROC curve\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
